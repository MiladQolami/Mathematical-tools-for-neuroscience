{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLuoArhI3sWOknmvBObSMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiladQolami/Mathematical-tools-for-neuroscience/blob/main/Machine_Learning/IntroToPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "PyTorch is an open-source machine learning library for Python, primarily developed by Facebook's AI Research lab (FAIR).\n",
        "\n",
        "Several giant tech companies like Meta and Microsoft use pytorch to bring machine learning to their products. Pytorch is #1 library for deep learning among developers. One of the main features of Pytorch is its advantages when it comes to using the power of GPUs.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aIQqkatfpN1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "O4h-EQM_QeDx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Tensors\n",
        "\n",
        "Tensors are fundemental data structrues in pytorch. We store infromation of input and output data in tensors. Tensors are similar to Numpy ndarrays but with additional features. So tensors can be considered as multidimensional matrices.\n",
        "\n",
        "Tensors can have any number of dimensions and different lengths along each dimension. For example a scalar is a tensor of rank 0, a vector is a tensor of rank 1 and a matrix is a tensor with rank 2.\n",
        "\n"
      ],
      "metadata": {
        "id": "IK4-InzLQs3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<center>\n",
        "<img src = 'https://raw.githubusercontent.com/MiladQolami/Mathematical-tools-for-neuroscience/main/Machine_Learning/tensor.jpg'>\n",
        "<center>"
      ],
      "metadata": {
        "id": "QzVaJdwfTgaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating tensors\n",
        "\n",
        "we can store different types of numerical data in tensors, like integers, floating numbers and complex numbers.\n",
        "\n",
        "Lect's create some tensors."
      ],
      "metadata": {
        "id": "CdyhCVLqXBqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = torch.tensor(4)  # tensor with rank or dimension 0, ie a scalar\n",
        "print(t0)\n",
        "t0.ndim   # This is tensor with 0 dimension\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqpP3O7dY5sa",
        "outputId": "7ae63641-0298-4b39-f9a3-660db048575f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([1.0,2.3,3.6])  # A 1D tensor, a vecrot\n",
        "print(t1)\n",
        "t1.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_qQ4bLUWOkg",
        "outputId": "db406abb-95d7-4b42-8cb1-129ee64c7074"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0000, 2.3000, 3.6000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.tensor([[1,2,3],\n",
        "                   [4,5,6]])   # A 2D tensor or a matrix\n",
        "print(t2)\n",
        "t2.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIJ0HboFYVJ7",
        "outputId": "079a77cf-806a-43e7-aa65-82422bc4a514"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor's data type\n",
        "\n",
        "We can change tensor's data type by passing an optional argument"
      ],
      "metadata": {
        "id": "Xdia7CW9q-K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2.dtype # t2 is tensor containg integers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM5GfnBYoVPU",
        "outputId": "e9c2ba76-0ab3-4e3a-c6a4-1b52b56d83b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.tensor([[1,2,3],\n",
        "                   [4,5,6]],dtype =torch.float16)"
      ],
      "metadata": {
        "id": "WgXqicyqr_m_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2.dtype"
      ],
      "metadata": {
        "id": "vKV2eIYAsYyo",
        "outputId": "ae505221-bd3e-47f3-dfaa-27d3121e1d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shape of a tensor\n",
        "\n",
        "We can get number of rows and columns by `.shape` method"
      ],
      "metadata": {
        "id": "pvCsLJSOdOSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2.shape # A 2D tensor with 2 rows and 3 columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trPhlEPwcJ7H",
        "outputId": "2d24a384-1825-46f9-8286-f8844daa9d3b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing a tensor\n",
        "\n",
        "Similar to Numpy arrays we can initialize a tensors with zeros, ones, random values, ..."
      ],
      "metadata": {
        "id": "gARyFjKZZ2zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_tensor = torch.zeros(2,5)  # A tensor with 2 rows and 5 columns with zeros\n",
        "print(zero_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj2ZeF_hZ1AL",
        "outputId": "0326ddce-a538-446f-c5f3-8d074684f56c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range_tensor = torch.arange(0,10,2)  # A tensor with values 0,2,4,6,8,10\n",
        "print(range_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--Hbx41Aauwc",
        "outputId": "49282ae2-7dc2-4934-f919-b634e0947308"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 2, 4, 6, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go to higher dimensions\n"
      ],
      "metadata": {
        "id": "1zWmyN88dho9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = torch.tensor([[[1,3,3],\n",
        "                    [2,5,3],\n",
        "                    [6,2,3]]])  # A 3D tensor or a cube, columns are in depth\n",
        "print(t3)\n",
        "t3.ndim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iympzTgndnMT",
        "outputId": "612690a3-b89e-49be-af56-9e977965be0b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 3, 3],\n",
            "         [2, 5, 3],\n",
            "         [6, 2, 3]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3.shape  # A 3D tensor with 1 row, 3 columns and 3 depth"
      ],
      "metadata": {
        "id": "f390tjCjeh9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9d16f8-4d53-440d-aa31-1dfffe68c20a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a tensor with shape (2,3,2)"
      ],
      "metadata": {
        "id": "B-Fs2qI-gdML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t3_2 = torch.tensor([[[1,3],\n",
        "                      [3,5],\n",
        "                      [6,4]],\n",
        "\n",
        "                     [[3,4],\n",
        "                      [1,3],\n",
        "                      [4,3]]])  # A 3D tensor with 2 rows, 3 columns and 2 depth\n",
        "print(t3_2)"
      ],
      "metadata": {
        "id": "e5DaQW4egmlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9a8e0a-ae70-41e4-9838-47736bf1cfcb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 3],\n",
            "         [3, 5],\n",
            "         [6, 4]],\n",
            "\n",
            "        [[3, 4],\n",
            "         [1, 3],\n",
            "         [4, 3]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3_2.shape"
      ],
      "metadata": {
        "id": "c3v75_7LhbX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a639b3-fa54-4a26-ecb2-651b3de4be9e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Generate a tensor with 3 rows, 2 columns and 2 depth\n",
        "my_tensor = ...\n",
        "print(my_tensor)\n",
        "print(my_tensor.shape)"
      ],
      "metadata": {
        "id": "xQkQ7Gbn-Y0R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "33c64a89-508c-482e-860f-0f07a0d5ec2b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ellipsis\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ellipsis' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-17c46a569738>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmy_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reductions Operations"
      ],
      "metadata": {
        "id": "PISmSW-eLlj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "a_tensor = torch.arange(start=0,end=20,step=2)\n",
        "\n",
        "# Some frequently used data summary statistics\n",
        "a_tensor.min(),a_tensor.max(),a_tensor.sum()"
      ],
      "metadata": {
        "id": "bPjQjsEBMYMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d18ea688-8350-42b8-fc89-9ff0281ac46e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(18), tensor(90))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_tensor.dtype"
      ],
      "metadata": {
        "id": "-ZH6qfqEP76a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`mean()` does not work when data type is too long or it is integer. To make it work we should change data type to a shorter data type"
      ],
      "metadata": {
        "id": "_T1fMzFBQDej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_tensor.type(torch.float32).mean()"
      ],
      "metadata": {
        "id": "5_ASoYdfQSyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding positional min and max"
      ],
      "metadata": {
        "id": "TZ441O_WRxXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_tensor.argmin()  # Returns index of minimum value\n",
        "a_tensor.argmax()  # Returns index of maximum value"
      ],
      "metadata": {
        "id": "3WdAClt7Rw1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random tensors\n",
        "\n",
        "Random tensors are important becuase in deep neural networks we start by setting weights to random values and then try to optimize those weieghts.\n",
        "\n",
        "`start with random values ==> look at your data ==> update your weights ==> look at your dagta ==> updata your weights`"
      ],
      "metadata": {
        "id": "gv0iG0ttG1ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_tensor = torch.rand(3,4)  # A tensor with random values\n",
        "print(rand_tensor)"
      ],
      "metadata": {
        "id": "WNnBUwCBHKdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reproduce the result when random processes is involved we usually seed the RNG.\n"
      ],
      "metadata": {
        "id": "v-qfTn-QaK3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(100)\n",
        "torch.rand(3)"
      ],
      "metadata": {
        "id": "l0M3YJCWaigU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Manipulatoin\n",
        "\n",
        "\n",
        "Indexing, similar to numpy, allows for accessing elements in a tensor through their indices. In any numpy-like array, indexing starts at 0, and when specifying ranges, it includes the starting index up to, but not including, the ending index. Additionally, negative indices can be used to refer to elements relative to the end of the list. This method of accessing elements is often called slicing.\n",
        "\n",
        "For instance, using the index [-1] will access the last element. The slice [1:3] captures the second and third elements. Furthermore, the slice [:-2] selects all elements up to, but excluding, the last two elements."
      ],
      "metadata": {
        "id": "8FrBh3NXDwYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([10, 20, 30, 40, 50])\n",
        "last_element = arr[-1]  # Outputs 50\n",
        "\n",
        "specific_elements = arr[1:3]  # Outputs [20, 30]\n",
        "\n",
        "\n",
        "all_but_last_two = arr[:-2]  # Outputs [10, 20, 30]\n"
      ],
      "metadata": {
        "id": "U-2yD_1wD4w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reshaping** tensors involves changing the structure of the data. Often, there's a need to convert 2D data into a 1D format or vice versa. To facilitate these transformations, the methods .flatten() and .reshape() are used.\n",
        "\n",
        "For instance:\n",
        "\n",
        "Flatten a 2D tensor into a 1D tensor:"
      ],
      "metadata": {
        "id": "M0Q9BoOTFwbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d = torch.tensor([[1, 2], [3, 4]])\n",
        "flattened_tensor = tensor_2d.flatten()  # Outputs: tensor([1, 2, 3, 4])\n"
      ],
      "metadata": {
        "id": "hFlHESOtF7WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape a 1D tensor into a 2D tensor:"
      ],
      "metadata": {
        "id": "lxJGtUorGXY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1d = torch.tensor([1, 2, 3, 4])\n",
        "reshaped_tensor = tensor_1d.reshape(2, 2)  # Outputs: tensor([[1, 2], [3, 4]])\n"
      ],
      "metadata": {
        "id": "AWksZO10GTK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Squeezing tensors**"
      ],
      "metadata": {
        "id": "vSIsVVUdHRIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tonsor_2d = torch.ones(1,5) # A 2D tensor with a single row\n",
        "tensor_1 = torch.tensor([1,1,1,1,1]) # A 1D tensor with a single row\n",
        "\n",
        "tensor_2d_to_1d = tonsor_2d.squeeze(0)\n",
        "print(tensor_2d_to_1d.ndim)"
      ],
      "metadata": {
        "id": "IJw80z9OI3xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Swapping Dimesions**\n",
        "\n",
        "Sometimes we need to swap dimensions so that our data is in correct form.It is similar to `.transpose` but in higher dimensions.\n"
      ],
      "metadata": {
        "id": "X6iowSaYK0x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_image = torch.randn(3,254,128)\n",
        "\n",
        "my_image_prime = my_image.permute(2,1,0)\n",
        "\n",
        "plt.imshow(my_image_prime)"
      ],
      "metadata": {
        "id": "er8nvHMwK59I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving between CPU & GPU\n",
        "\n",
        "Data can be stored on both the CPU and GPU, but utilizing the GPU for data processing can speed up operations, especially for tasks involving large-scale matrix calculations or deep learning.\n",
        "\n",
        "\n",
        "Moving data between CPU and GPU can be time-consuming. It’s best to minimize these transfers by keeping data on the GPU as much as possible once it’s been loaded there.\n",
        "\n"
      ],
      "metadata": {
        "id": "np_l4vj6-CNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,3])\n",
        "x.device  # CPU"
      ],
      "metadata": {
        "id": "eFuRcvsT97Ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8cf0784-6e7d-47fa-fc61-e63afc102484"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Moving the variabl x to GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "x = x.to(device)\n",
        "x.device"
      ],
      "metadata": {
        "id": "DrfpcUYG-WT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946b054a-7a49-4d4b-d26c-79ee6719f94a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is wise to make sure the defaut device is GPU if available at the begining of the code."
      ],
      "metadata": {
        "id": "iFqt37iN_iNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_device():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    return device"
      ],
      "metadata": {
        "id": "kXj56rlY_iCL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "One of the essential steps in building models is preparing and loading data efficiently. PyTorch provides robust utilities for handling data, including custom datasets and data loaders that can manage batching, shuffling, and parallel loading.\n",
        "\n",
        "**But why proper data loading is essential?**\n",
        "\n",
        "* **Performance**: Proper data handling ensures that the GPU is fed with data without delays, preventing bottlenecks.\n",
        "* **Scalability**: As datasets grow, efficient loading mechanisms become vital.\n",
        "* **Preprocessing**: Applying transformations and augmentations can improve model performance.\n",
        "\n",
        "In this section, we'll explore how to load and preprocess data using PyTorch's `Dataset` and `DataLoader` classes. We'll work through a real example using the popular MNIST dataset of handwritten digits."
      ],
      "metadata": {
        "id": "psqSJHHb_hVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "m1dc85KhG7ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What is `torch.utils.data.Dataset`?\n",
        "\n",
        "`Dataset` is an abstract class that represents a dataset. It serves as a blueprint for creating custom datasets.\n",
        "\n",
        "Purpose:\n",
        "\n",
        "To allow users to create their own datasets by subclassing `Dataset`.\n",
        "\n",
        "When you have custom data (e.g., images in a folder, data from a database, etc.), you can create a class that inherits from Dataset and implements the necessary methods.\n",
        "\n",
        "\n",
        "What is `torch.utils.data.DataLoader`?\n",
        "\n",
        "DataLoader is a PyTorch class that provides an iterable over a dataset with support for automatic batching, shuffling, and loading data in parallel using multiprocessing workers.\n",
        "\n",
        "Purpose:\n",
        "\n",
        "To facilitate the efficient loading of data during training and evaluation of models.\n",
        "Handles batching of data samples, which is essential for training neural networks in mini-batches.\n",
        "Supports shuffling of data to improve model generalization.\n",
        "Can load data in parallel, which speeds up data preparation.\n",
        "Usage:\n",
        "\n",
        "Wrap a Dataset (either a built-in dataset or a custom one) with a DataLoader to create an iterable over the data.\n"
      ],
      "metadata": {
        "id": "RtHw3cZ_HKba"
      }
    }
  ]
}